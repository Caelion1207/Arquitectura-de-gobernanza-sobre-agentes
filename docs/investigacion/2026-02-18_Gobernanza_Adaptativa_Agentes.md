# Gobernanza Adaptativa de Agentes Autónomos: Un Enfoque desde la Legitimidad Dinámica y la Transparencia Computacional

## 1. Pregunta de Investigación

¿Cómo puede un marco de gobernanza adaptativa, fundamentado en los principios de legitimidad dinámica y transparencia computacional, asegurar la alineación ética y la viabilidad operativa de sistemas de inteligencia artificial autónomos en entornos sociotécnicos complejos y cambiantes?

## 2. Marco Teórico: Viabilidad, Control y Legitimidad

Este estudio se fundamenta en una tríada conceptual para abordar la gobernanza de la IA: la **viabilidad** de los sistemas, el **control** sobre sus acciones y la **legitimidad** de su operación. La viabilidad se refiere a la capacidad de un sistema para mantenerse y operar efectivamente en su entorno. El control se relaciona con los mecanismos para dirigir y restringir el comportamiento del sistema. La legitimidad, en este contexto, se define como la aceptabilidad de la autoridad del sistema y sus decisiones por parte de los actores humanos y sociales. Este marco se nutre de las teorías de la cibernética, la ciencia política y la sociología de la tecnología.

## 3. Estado del Arte: Síntesis de Investigaciones Doctorales Recientes

El campo de la gobernanza de IA está evolucionando rápidamente, como lo demuestran tres recientes disertaciones doctorales que informan este análisis.

- **Theodorou (2019)** [1] argumenta que la **transparencia** es un pilar para la gobernanza de la IA. A través del desarrollo de herramientas como ABOD3, demuestra empíricamente que la visualización de los mecanismos de decisión de un agente reduce la tendencia a antropomorfizarlo y permite a los usuarios calibrar su confianza. Su trabajo subraya la necesidad de una "transparencia computacional" como un requisito de diseño fundamental para la atribución de responsabilidad.

- **Maas (2021)** [2] aborda la gobernanza de la IA desde la perspectiva del **cambio**. Propone un marco que considera tres facetas: el cambio sociotécnico, la disrupción de la gobernanza y la complejidad del régimen. Sostiene que los regímenes de gobernanza de la IA deben ser **eficaces, resilientes y coherentes** para adaptarse a las transformaciones continuas, introduciendo una perspectiva dinámica y adaptativa indispensable.

- **Heinisuo (2025)** [3] investiga la implementación de la IA en los servicios públicos a través del concepto de **mutualidad**. Su análisis, centrado en la administración pública finlandesa, revela que la colaboración y las relaciones interdependientes entre todos los actores (desarrolladores, usuarios, reguladores) son cruciales para una implementación responsable. La "mutualidad" emerge como un factor clave para superar la fragmentación y construir modelos de gobernanza inclusivos y multinivel.

| Tesis | Enfoque Principal | Contribución Clave a la Gobernanza | Concepto Central |
| :--- | :--- | :--- | :--- |
| Theodorou (2019) | Transparencia y Diseño | Herramientas para la interpretabilidad y la responsabilidad. | Transparencia Computacional |
| Maas (2021) | Adaptación al Cambio | Marcos para la resiliencia y coherencia regulatoria. | Gobernanza Adaptativa |
| Heinisuo (2025) | Colaboración e Implementación | Énfasis en la colaboración multi-actor y el aprendizaje. | Mutualidad |

## 4. Análisis Crítico: Paradojas y Tensiones Emergentes

La síntesis de estas tres perspectivas revela una tensión fundamental: la **paradoja entre la transparencia estática y la gobernanza dinámica**. Mientras que Theodorou ofrece herramientas para una transparencia en tiempo real (una "instantánea" del estado del agente), Maas nos recuerda que tanto la tecnología como el entorno social están en un estado de flujo perpetuo. Una transparencia meramente puntual puede ser insuficiente, e incluso engañosa, si no se integra en un marco que gestione el cambio. Por otro lado, el ideal de "mutualidad" de Heinisuo, aunque deseable, se enfrenta al desafío de la escala y la complejidad en sistemas globales. ¿Cómo se logra un consenso significativo entre actores con intereses divergentes y en constante cambio?

## 5. Hipótesis Propia: Hacia la Legitimidad Dinámica

En respuesta a estas tensiones, **propongo** un modelo de **legitimidad dinámica** como el eje central para la gobernanza de agentes autónomos. **Sostengo** que la legitimidad de un sistema de IA no es un atributo estático conferido en el momento del diseño, sino un estado que debe ser continuamente negociado y reconstruido a través de la interacción con su entorno. **Argumento** que un sistema demuestra legitimidad dinámica cuando su comportamiento no solo es transparente (Theodorou), sino que también se adapta de manera coherente y predecible a las nuevas normas y expectativas que surgen del cambio sociotécnico (Maas), en un proceso que refleja los principios de colaboración y feedback de la mutualidad (Heinisuo). **Concluyo**, por tanto, que la viabilidad a largo plazo de los sistemas autónomos no depende de una optimización de la eficiencia, sino de su capacidad para mantener esta legitimidad dinámica.

## 6. Implicaciones Prácticas

Este enfoque tiene implicaciones directas para el diseño de sistemas de IA y su regulación:

1.  **Sistemas de Monitoreo de Legitimidad:** Se deben desarrollar sistemas que no solo auditen las decisiones de la IA, sino que también monitoreen la percepción de su legitimidad entre los diferentes grupos de stakeholders.
2.  **Protocolos de Adaptación Regulada:** Los agentes autónomos deberían incorporar protocolos que les permitan solicitar una revisión o actualización de sus propios objetivos y restricciones cuando detecten un desajuste significativo con las expectativas de su entorno.
3.  **Mercados de Gobernanza:** Se podrían explorar mecanismos de mercado o cuasi-mercado donde los stakeholders puedan expresar sus preferencias y "apostar" por diferentes configuraciones de gobernanza, creando un sistema de incentivos para la adaptación.

## 7. Limitaciones Explícitas

Esta investigación, de carácter conceptual, presenta varias limitaciones. Primero, la noción de "legitimidad dinámica" requiere una operacionalización mucho más detallada y métricas específicas que no se desarrollan aquí. Segundo, la implementación práctica de los mecanismos propuestos enfrenta enormes desafíos técnicos y sociales, como la posibilidad de manipulación y la dificultad de agregar preferencias heterogéneas. Tercero, este análisis se basa en una selección limitada de literatura y no considera otras importantes tradiciones de pensamiento en la gobernanza de la IA. La validación de esta hipótesis requeriría la construcción de simulaciones de agentes y el diseño de experimentos en entornos controlados.

## 8. Sección Pedagógica: Sistemas Dinámicos y Gobernanza de IA

La gobernanza de la IA puede ser entendida como un problema de **sistemas dinámicos complejos**. Un sistema dinámico es aquel cuyo estado evoluciona con el tiempo. En nuestro caso, el "estado" del sistema de gobernanza incluye no solo el comportamiento del agente de IA, sino también las regulaciones, las normas sociales, y las expectativas de los usuarios. Estos elementos están interconectados en un bucle de retroalimentación (feedback loop):

-   **Retroalimentación Negativa (Estabilizadora):** Las regulaciones y auditorías actúan como mecanismos de retroalimentación negativa, corrigiendo las desviaciones del comportamiento deseado del agente y manteniendo la estabilidad del sistema.
-   **Retroalimentación Positiva (Desestabilizadora):** La innovación tecnológica rápida o los cambios abruptos en la opinión pública pueden actuar como fuerzas de retroalimentación positiva, empujando al sistema hacia nuevos estados, a veces de forma impredecible.

El enfoque de la **legitimidad dinámica** busca diseñar mecanismos de gobernanza que puedan gestionar ambos tipos de retroalimentación, permitiendo que el sistema se adapte y evolucione sin colapsar. Se trata de encontrar un equilibrio entre la estabilidad (control) y la adaptabilidad (viabilidad), un desafío central en la teoría de control de sistemas complejos.

---

## Referencias

[1] Theodorou, A. (2019). *AI Governance Through a Transparency Lens*. Doctoral Thesis, University of Bath. Recuperado de https://researchportal.bath.ac.uk/en/studentTheses/ai-governance-through-a-transparency-lens/

[2] Maas, M. M. (2021). *Artificial Intelligence Governance under Change - Foundations, Facets, Frameworks*. PhD in Law, University of Copenhagen. Recuperado de https://matthijsmaas.com/uploads/Maas%20-%202021%20-%20PhD%20Dissertation%20-%20Artificial%20Intelligence%20Governance%20Under%20Change%20-%20monograph.pdf

[3] Heinisuo, E. (2025). *Artificial Intelligence in Public Services: Mutuality in the organisational governance of AI implementation*. Doctoral Dissertation, Tampere University. Recuperado de https://cris.vtt.fi/en/publications/artificial-intelligence-in-public-services-mutuality-in-the-organ/
